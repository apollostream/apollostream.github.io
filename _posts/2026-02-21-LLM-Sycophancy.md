---
layout: post
title: '"Sir! Yes, sir!"'
published: true
---

![LLM Sycophancy](../images/llm-sycophancy-tensions-with-honesty.png)

*LLM sycophancy: the tensions are real when you demand intellectual honesty (generated by Gemini 3 Pro with Perplexity.AI).*

---

If you've used ChatGPT and the like for very long, you're certainly aware of just how sycophantic LLMs can be: they'll agree with you on just about anything.  One of the reasons I took up this pursuit of instilling intellectual honesty into an LLM was that I felt like I couldn't make headway on understanding any issue that was mildly complex and controversial by chatting with an LLM.  It required more: alternatives considering, evidence seeking, uncertainty acknowledgement, multiple viewpoints, rigorous reasoning.  None of these are inherent to an LLM through its pre-training and reinforcement learning (RLHF) or its alignment and guardrails.

So, maybe BFIH is a means of breaking LLMs of the habits of sycophancy.  And, an analysis suggested by Claude Opus 4.6 through Claude Code seemed to confirm that BFIH does indeed impose at minimum a tension between the LLM's built-in tendencies to be agreeable and my mandates for it to be intellectually honest -- at least that's what it said to me, but even that could be an example of sycophancy!

Oh, well. I'm not going to resolve that here. But I did have BFIH take up the topic with respect to generic intellectual honesty injected into an LLM through context engineering -- given that I'm using the SOTA foundation models and won't be post-training/fine-tuning LLMs for my own purposes anytime soon.

---

**The proposition to analyze:**

> **_"Can LLM sycophancy be mitigated by context engineering demanding intellectual honesty?"_**

**The upshot:** To some extent "yes" but it takes more than that to make it stick.

---

### Synopsis

Below is the plain-language synopsis of the BFIH findings, which includes a link to the full BFIH analysis report.

<div align="center">⁂</div>

{% include LLM-Sycophancy_magazine_synopsis.md %}

---

Thank you for your time and mindshare,

-Michael L. Thompson ([LinkedIn profile](https://www.linkedin.com/in/mlthomps))

<div align="center">⁂</div>
